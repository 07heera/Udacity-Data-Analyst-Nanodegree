{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2 - Intro to Data Science - Quiz\n",
    "_Author: Ly Vinh Hung (Tommy) _"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandasql\n",
    "import csv\n",
    "filename = \"weather_underground.csv\"\n",
    "turnstile_weather = \"turnstile_data_master_with_weather.csv\"\n",
    "\n",
    "from sympy import init_printing\n",
    "init_printing()\n",
    "import sympy as sym\n",
    "from sympy import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 2 - Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   count(*)\n",
      "0        10\n"
     ]
    }
   ],
   "source": [
    "#ps 2.1\n",
    "\n",
    "def num_rainy_days(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return one column and\n",
    "    one row - a count of the number of days in the dataframe where\n",
    "    the rain column is equal to 1 (i.e., the number of days it\n",
    "    rained).  The dataframe will be titled 'weather_data'. You'll\n",
    "    need to provide the SQL query.  You might find SQL's count function\n",
    "    useful for this exercise.  You can read more about it here:\n",
    "    \n",
    "    https://dev.mysql.com/doc/refman/5.1/en/counting-rows.html\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://www.dropbox.com/s/7sf0yqc9ykpq3w8/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = 'select count(*)  from weather_data where rain == 1'\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    rainy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return rainy_days\n",
    "\n",
    "print num_rainy_days(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fog  max(cast (maxtempi as integer))\n",
      "0    0                               86\n",
      "1    1                               81\n"
     ]
    }
   ],
   "source": [
    "#ps 2.2\n",
    "def max_temp_aggregate_by_fog(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return two columns and\n",
    "    two rows - whether it was foggy or not (0 or 1) and the max\n",
    "    maxtempi for that fog value (i.e., the maximum max temperature\n",
    "    for both foggy and non-foggy days).  The dataframe will be \n",
    "    titled 'weather_data'. You'll need to provide the SQL query.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://www.dropbox.com/s/7sf0yqc9ykpq3w8/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = 'select fog, max(cast (maxtempi as integer)) from weather_data group by fog'\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    foggy_days = pandasql.sqldf(q.lower(), locals())\n",
    "    return foggy_days\n",
    "print max_temp_aggregate_by_fog(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg(cast (meantempi as integer))\n",
      "0                         65.111111\n"
     ]
    }
   ],
   "source": [
    "#ps 2.3\n",
    "\n",
    "def avg_weekend_temperature(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data.  The SQL query should return one column and\n",
    "    one row - the average meantempi on days that are a Saturday\n",
    "    or Sunday (i.e., the the average mean temperature on weekends).\n",
    "    The dataframe will be titled 'weather_data' and you can access\n",
    "    the date in the dataframe via the 'date' column.\n",
    "    \n",
    "    You'll need to provide  the SQL query.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    Also, you can convert dates to days of the week via the 'strftime' keyword in SQL.\n",
    "    For example, cast (strftime('%w', date) as integer) will return 0 if the date\n",
    "    is a Sunday or 6 if the date is a Saturday.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://www.dropbox.com/s/7sf0yqc9ykpq3w8/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT \n",
    "    avg(cast (meantempi as integer)) \n",
    "    FROM \n",
    "    weather_data \n",
    "    WHERE\n",
    "    cast (strftime('%w', date) as integer) in (0,6)\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    mean_temp_weekends = pandasql.sqldf(q.lower(), locals())\n",
    "    return mean_temp_weekends\n",
    "print avg_weekend_temperature(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   avg(mintempi)\n",
      "0          61.25\n"
     ]
    }
   ],
   "source": [
    "# ps 2.4\n",
    "\n",
    "def avg_min_temperature(filename):\n",
    "    '''\n",
    "    This function should run a SQL query on a dataframe of\n",
    "    weather data. More specifically you want to find the average\n",
    "    minimum temperature (mintempi column of the weather dataframe) on \n",
    "    rainy days where the minimum temperature is greater than 55 degrees.\n",
    "    \n",
    "    You might also find that interpreting numbers as integers or floats may not\n",
    "    work initially.  In order to get around this issue, it may be useful to cast\n",
    "    these numbers as integers.  This can be done by writing cast(column as integer).\n",
    "    So for example, if we wanted to cast the maxtempi column as an integer, we would actually\n",
    "    write something like where cast(maxtempi as integer) = 76, as opposed to simply \n",
    "    where maxtempi = 76.\n",
    "    \n",
    "    You can see the weather data that we are passing in below:\n",
    "    https://www.dropbox.com/s/7sf0yqc9ykpq3w8/weather_underground.csv\n",
    "    '''\n",
    "    weather_data = pandas.read_csv(filename)\n",
    "\n",
    "    q = \"\"\"\n",
    "    SELECT \n",
    "    avg(mintempi)\n",
    "    FROM \n",
    "    weather_data \n",
    "    WHERE \n",
    "    rain == 1 and mintempi > 55\n",
    "    \"\"\"\n",
    "    \n",
    "    #Execute your SQL command against the pandas frame\n",
    "    avg_min_temp_rainy = pandasql.sqldf(q.lower(), locals())\n",
    "    return avg_min_temp_rainy\n",
    "\n",
    "print avg_min_temperature(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ps 2.5\n",
    "filenames = [\"turnstile_110507.txt\"]\n",
    "import csv\n",
    "\n",
    "def fix_turnstile_data(filenames):\n",
    "    '''\n",
    "    Filenames is a list of MTA Subway turnstile text files. A link to an example\n",
    "    MTA Subway turnstile text file can be seen at the URL below:\n",
    "    http://web.mta.info/developers/data/nyct/turnstile/turnstile_110507.txt\n",
    "    \n",
    "    As you can see, there are numerous data points included in each row of the\n",
    "    a MTA Subway turnstile text file. \n",
    "\n",
    "    You want to write a function that will update each row in the text\n",
    "    file so there is only one entry per row. A few examples below:\n",
    "    A002,R051,02-00-00,05-28-11,00:00:00,REGULAR,003178521,001100739\n",
    "    A002,R051,02-00-00,05-28-11,04:00:00,REGULAR,003178541,001100746\n",
    "    A002,R051,02-00-00,05-28-11,08:00:00,REGULAR,003178559,001100775\n",
    "    \n",
    "    Write the updates to a different text file in the format of \"updated_\" + filename.\n",
    "    For example:\n",
    "        1) if you read in a text file called \"turnstile_110521.txt\"\n",
    "        2) you should write the updated data to \"updated_turnstile_110521.txt\"\n",
    "\n",
    "    The order of the fields should be preserved. Remember to read through the \n",
    "    Instructor Notes below for more details on the task. \n",
    "    \n",
    "    In addition, here is a CSV reader/writer introductory tutorial:\n",
    "    http://goo.gl/HBbvyy\n",
    "    \n",
    "    You can see a sample of the turnstile text file that's passed into this function\n",
    "    and the the corresponding updated file in the links below:\n",
    "    \n",
    "    Sample input file:\n",
    "    https://www.dropbox.com/s/mpin5zv4hgrx244/turnstile_110528.txt\n",
    "    Sample updated file:\n",
    "    https://www.dropbox.com/s/074xbgio4c39b7h/solution_turnstile_110528.txt\n",
    "    '''\n",
    "    for name in filenames:\n",
    "        #create file input object f_in to work with filenames  \n",
    "        f_in = open(name, 'r')\n",
    "        f_out = open('updated_' + name, 'w')\n",
    "        #create csv reader and writer based on file object\n",
    "        reader_in = csv.reader(f_in, delimiter = ',')\n",
    "        writer_out = csv.writer(f_out, delimiter = ',')\n",
    "       \n",
    "        for line in reader_in:\n",
    "            header = line[:3]\n",
    "            for i in xrange(3, len(line), 5):\n",
    "                writer_out.writerow(header + line[i:i+5])\n",
    "                \n",
    "fix_turnstile_data(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ps 2.6\n",
    "def create_master_turnstile_file(filenames, output_file):\n",
    "    '''\n",
    "    Write a function that takes the files in the list filenames, which all have the \n",
    "    columns 'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn', and consolidates\n",
    "    them into one file located at output_file.  There should be ONE row with the column\n",
    "    headers, located at the top of the file. The input files do not have column header\n",
    "    rows of their own.\n",
    "    \n",
    "    For example, if file_1 has:\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    \n",
    "    and another file, file_2 has:\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    \n",
    "    We need to combine file_1 and file_2 into a master_file like below:\n",
    "     'C/A, UNIT, SCP, DATEn, TIMEn, DESCn, ENTRIESn, EXITSn'\n",
    "    line 1 ...\n",
    "    line 2 ...\n",
    "    line 3 ...\n",
    "    line 4 ...\n",
    "    line 5 ...\n",
    "    '''\n",
    "    with open(output_file, 'w') as master_file:\n",
    "        master_file.write('C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\\n')\n",
    "        for filename in filenames:\n",
    "            # your code here\n",
    "            master_file.write(''.join(open(filename).readlines()))\n",
    "        master_file.close()  \n",
    "        \n",
    "create_master_turnstile_file(filenames, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 2.7\n",
    "import pandas\n",
    "\n",
    "def filter_by_regular(filename):\n",
    "    '''\n",
    "    This function should read the csv file located at filename into a pandas dataframe,\n",
    "    and filter the dataframe to only rows where the 'DESCn' column has the value 'REGULAR'.\n",
    "    \n",
    "    For example, if the pandas dataframe is as follows:\n",
    "    ,C/A,UNIT,SCP,DATEn,TIMEn,DESCn,ENTRIESn,EXITSn\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    1,A002,R051,02-00-00,05-01-11,04:00:00,DOOR,3144335,1088159\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    3,A002,R051,02-00-00,05-01-11,12:00:00,DOOR,3144424,1088231\n",
    "    \n",
    "    The dataframe will look like below after filtering to only rows where DESCn column\n",
    "    has the value 'REGULAR':\n",
    "    0,A002,R051,02-00-00,05-01-11,00:00:00,REGULAR,3144312,1088151\n",
    "    2,A002,R051,02-00-00,05-01-11,08:00:00,REGULAR,3144353,1088177\n",
    "    '''\n",
    "    \n",
    "    turnstile_data = pandas.read_csv(filename)\n",
    "    turnstile_data = turnstile_data[turnstile_data['DESCn']=='REGULAR']\n",
    "    # more of your code here\n",
    "    return turnstile_data  \n",
    "print filter_by_regular(filename).head()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 2.8\n",
    "\n",
    "def get_hourly_entries(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative entry numbers to a count of entries since the last reading\n",
    "    (i.e., entries since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called ENTRIESn_hourly\n",
    "       2) Assign to the column the difference between ENTRIESn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 1.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Examples of what your dataframe should look like at the end of this exercise:\n",
    "    \n",
    "           C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly\n",
    "    0     A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                1\n",
    "    1     A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23\n",
    "    2     A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18\n",
    "    3     A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71\n",
    "    4     A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170\n",
    "    5     A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214\n",
    "    6     A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87\n",
    "    7     A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10\n",
    "    8     A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36\n",
    "    9     A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153\n",
    "    10    A002  R051  02-00-00  05-02-11  16:00:00  REGULAR   3145337   1088823              243\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    '''\n",
    "    #your code here\n",
    "    df['ENTRIESn_hourly'] = df['ENTRIESn'] - df['ENTRIESn'].shift(periods=1)\n",
    "    df['ENTRIESn_hourly'] = df['ENTRIESn_hourly'].fillna(1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 2.9\n",
    "\n",
    "def get_hourly_exits(df):\n",
    "    '''\n",
    "    The data in the MTA Subway Turnstile data reports on the cumulative\n",
    "    number of entries and exits per row.  Assume that you have a dataframe\n",
    "    called df that contains only the rows for a particular turnstile machine\n",
    "    (i.e., unique SCP, C/A, and UNIT).  This function should change\n",
    "    these cumulative exit numbers to a count of exits since the last reading\n",
    "    (i.e., exits since the last row in the dataframe).\n",
    "    \n",
    "    More specifically, you want to do two things:\n",
    "       1) Create a new column called EXITSn_hourly\n",
    "       2) Assign to the column the difference between EXITSn of the current row \n",
    "          and the previous row. If there is any NaN, fill/replace it with 0.\n",
    "    \n",
    "    You may find the pandas functions shift() and fillna() to be helpful in this exercise.\n",
    "    \n",
    "    Example dataframe below:\n",
    "\n",
    "          Unnamed: 0   C/A  UNIT       SCP     DATEn     TIMEn    DESCn  ENTRIESn    EXITSn  ENTRIESn_hourly  EXITSn_hourly\n",
    "    0              0  A002  R051  02-00-00  05-01-11  00:00:00  REGULAR   3144312   1088151                0              0\n",
    "    1              1  A002  R051  02-00-00  05-01-11  04:00:00  REGULAR   3144335   1088159               23              8\n",
    "    2              2  A002  R051  02-00-00  05-01-11  08:00:00  REGULAR   3144353   1088177               18             18\n",
    "    3              3  A002  R051  02-00-00  05-01-11  12:00:00  REGULAR   3144424   1088231               71             54\n",
    "    4              4  A002  R051  02-00-00  05-01-11  16:00:00  REGULAR   3144594   1088275              170             44\n",
    "    5              5  A002  R051  02-00-00  05-01-11  20:00:00  REGULAR   3144808   1088317              214             42\n",
    "    6              6  A002  R051  02-00-00  05-02-11  00:00:00  REGULAR   3144895   1088328               87             11\n",
    "    7              7  A002  R051  02-00-00  05-02-11  04:00:00  REGULAR   3144905   1088331               10              3\n",
    "    8              8  A002  R051  02-00-00  05-02-11  08:00:00  REGULAR   3144941   1088420               36             89\n",
    "    9              9  A002  R051  02-00-00  05-02-11  12:00:00  REGULAR   3145094   1088753              153            333\n",
    "    '''\n",
    "    \n",
    "    #your code here\n",
    "    df['EXITSn_hourly'] = df['EXITSn'] - df['EXITSn'].shift(periods=1)\n",
    "    df['EXITSn_hourly'] = df['EXITSn_hourly'].fillna(0)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 2.10\n",
    "\n",
    "def time_to_hour(time):\n",
    "    '''\n",
    "    Given an input variable time that represents time in the format of:\n",
    "    \"00:00:00\" (hour:minutes:seconds)\n",
    "    \n",
    "    Write a function to extract the hour part from the input variable time\n",
    "    and return it as an integer. For example:\n",
    "        1) if hour is 00, your code should return 0\n",
    "        2) if hour is 01, your code should return 1\n",
    "        3) if hour is 21, your code should return 21\n",
    "        \n",
    "    Please return hour as an integer.\n",
    "    '''\n",
    "    \n",
    "    hour = float(time.split(':')[0])\n",
    "    return hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 2.11\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def reformat_subway_dates(date):\n",
    "    '''\n",
    "    The dates in our subway data are formatted in the format month-day-year.\n",
    "    The dates in our weather underground data are formatted year-month-day.\n",
    "    \n",
    "    In order to join these two data sets together, we'll want the dates formatted\n",
    "    the same way.  Write a function that takes as its input a date in the MTA Subway\n",
    "    data format, and returns a date in the weather underground format.\n",
    "    \n",
    "    Hint: \n",
    "    There are a couple of useful functions in the datetime library that will\n",
    "    help on this assignment, called strptime and strftime. \n",
    "    More info can be seen here and further in the documentation section:\n",
    "    http://docs.python.org/2/library/datetime.html#datetime.datetime.strptime\n",
    "    '''\n",
    "    date_formatted = datetime.strptime(date, '%m-%d-%y').strftime('%Y-%m-%d')\n",
    "    return date_formatted\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set 3 -  Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 3.1 -  Data analysis\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "turnstile_weather = pd.read_csv(\"turnstile_data_master_with_weather.csv\")\n",
    "\n",
    "def entries_histogram(turnstile_weather):\n",
    "    '''\n",
    "    Before we perform any analysis, it might be useful to take a\n",
    "    look at the data we're hoping to analyze. More specifically, let's \n",
    "    examine the hourly entries in our NYC subway data and determine what\n",
    "    distribution the data follows. This data is stored in a dataframe\n",
    "    called turnstile_weather under the ['ENTRIESn_hourly'] column.\n",
    "    \n",
    "    Let's plot two histograms on the same axes to show hourly\n",
    "    entries when raining vs. when not raining. Here's an example on how\n",
    "    to plot histograms with pandas and matplotlib:\n",
    "    turnstile_weather['column_to_graph'].hist()\n",
    "    \n",
    "    Your histogram may look similar to bar graph in the instructor notes below.\n",
    "    \n",
    "    You can read a bit about using matplotlib and pandas to plot histograms here:\n",
    "    http://pandas.pydata.org/pandas-docs/stable/visualization.html#histograms\n",
    "    \n",
    "    You can see the information contained within the turnstile weather data here:\n",
    "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv\n",
    "    '''\n",
    "    \n",
    "    turnstile_weather = pd.read_csv(\"turnstile_data_master_with_weather.csv\")\n",
    "    plt.figure()\n",
    "    turnstile_weather[turnstile_weather['rain'] == 0]['ENTRIESn_hourly'].hist(bins=180, alpha = 0.8, label=\"No rain\").set_xlim([0, 6000]) \n",
    "    turnstile_weather[turnstile_weather['rain'] == 1]['ENTRIESn_hourly'].hist(bins=180, alpha = 0.8, label=\"Rain\").set_xlim([0, 6000])\n",
    "    plt.legend()\n",
    "    return plt\n",
    "\n",
    "print entries_histogram(turnstile_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 3.3\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import pandas\n",
    "\n",
    "def mann_whitney_plus_means(turnstile_weather):\n",
    "    '''\n",
    "    This function will consume the turnstile_weather dataframe containing\n",
    "    our final turnstile weather data. \n",
    "    \n",
    "    You will want to take the means and run the Mann Whitney U-test on the \n",
    "    ENTRIESn_hourly column in the turnstile_weather dataframe.\n",
    "    \n",
    "    This function should return:\n",
    "        1) the mean of entries with rain\n",
    "        2) the mean of entries without rain\n",
    "        3) the Mann-Whitney U-statistic and p-value comparing the number of entries\n",
    "           with rain and the number of entries without rain\n",
    "    \n",
    "    You should feel free to use scipy's Mann-Whitney implementation, and you \n",
    "    might also find it useful to use numpy's mean function.\n",
    "    \n",
    "    Here are the functions' documentation:\n",
    "    http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html\n",
    "    \n",
    "    You can look at the final turnstile weather data at the link below:\n",
    "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv\n",
    "    '''\n",
    "    \n",
    "    ### YOUR CODE HERE ###\n",
    "    \n",
    "    with_rain = turnstile_weather[turnstile_weather['rain'] == 1]['ENTRIESn_hourly']\n",
    "    \n",
    "    without_rain = turnstile_weather[turnstile_weather['rain'] == 0]['ENTRIESn_hourly']\n",
    "    \n",
    "    with_rain_mean = with_rain.mean()\n",
    "    \n",
    "    without_rain_mean = without_rain.mean()\n",
    "\n",
    "    U, p = scipy.stats.mannwhitneyu(with_rain, without_rain)\n",
    "    \n",
    "    return with_rain_mean, without_rain_mean, U, p # leave this line for the grader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 3.5\n",
    "\n",
    "import numpy as np\n",
    "import pandas\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\"\"\"\n",
    "In this question, you need to:\n",
    "1) implement the linear_regression() procedure\n",
    "2) Select features (in the predictions procedure) and make predictions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def linear_regression(features, values):\n",
    "    \"\"\"\n",
    "    Perform linear regression given a data set with an arbitrary number of features.\n",
    "    \n",
    "    This can be the same code as in the lesson #3 exercise.\n",
    "    \"\"\"\n",
    " \n",
    "    features = sm.add_constant(features)\n",
    "    model = sm.OLS(values, features)\n",
    "    results = model.fit()\n",
    "    intercept = results.params[0]\n",
    "    params = results.params[1:]\n",
    "    \n",
    "    return intercept, params\n",
    "\n",
    "def predictions(dataframe):\n",
    "    '''\n",
    "    The NYC turnstile data is stored in a pandas dataframe called weather_turnstile.\n",
    "    Using the information stored in the dataframe, let's predict the ridership of\n",
    "    the NYC subway using linear regression with gradient descent.\n",
    "    \n",
    "    You can download the complete turnstile weather dataframe here:\n",
    "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv    \n",
    "    \n",
    "    Your prediction should have a R^2 value of 0.40 or better.\n",
    "    You need to experiment using various input features contained in the dataframe. \n",
    "    We recommend that you don't use the EXITSn_hourly feature as an input to the \n",
    "    linear model because we cannot use it as a predictor: we cannot use exits \n",
    "    counts as a way to predict entry counts. \n",
    "    \n",
    "    Note: Due to the memory and CPU limitation of our Amazon EC2 instance, we will\n",
    "    give you a random subet (~10%) of the data contained in \n",
    "    turnstile_data_master_with_weather.csv. You are encouraged to experiment with \n",
    "    this exercise on your own computer, locally. If you do, you may want to complete Exercise\n",
    "    8 using gradient descent, or limit your number of features to 10 or so, since ordinary\n",
    "    least squares can be very slow for a large number of features.\n",
    "    \n",
    "    If you receive a \"server has encountered an error\" message, that means you are \n",
    "    hitting the 30-second limit that's placed on running your program. Try using a\n",
    "    smaller number of features.\n",
    "    '''\n",
    "   \n",
    "    features = dataframe[['rain', 'precipi', 'Hour', 'meantempi', 'meanwindspdi']]\n",
    "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
    "    features = features.join(dummy_units)\n",
    "    \n",
    "    # Values\n",
    "    values = dataframe['ENTRIESn_hourly']\n",
    "\n",
    "    # Perform linear regression\n",
    "    intercept, params = linear_regression(features, values)\n",
    "    \n",
    "    predictions = intercept + np.dot(features, params)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 3.6\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_residuals(turnstile_weather, predictions):\n",
    "    '''\n",
    "    Using the same methods that we used to plot a histogram of entries\n",
    "    per hour for our data, why don't you make a histogram of the residuals\n",
    "    (that is, the difference between the original hourly entry data and the predicted values).\n",
    "    Try different binwidths for your histogram.\n",
    "\n",
    "    Based on this residual histogram, do you have any insight into how our model\n",
    "    performed?  Reading a bit on this webpage might be useful:\n",
    "\n",
    "    http://www.itl.nist.gov/div898/handbook/pri/section2/pri24.htm\n",
    "    '''\n",
    "    plt.figure()\n",
    "    (turnstile_weather['ENTRIESn_hourly'] - predictions).hist(bins=100)\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 3.7\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "def compute_r_squared(data, predictions):\n",
    "    '''\n",
    "    In exercise 5, we calculated the R^2 value for you. But why don't you try and\n",
    "    and calculate the R^2 value yourself.\n",
    "    \n",
    "    Given a list of original data points, and also a list of predicted data points,\n",
    "    write a function that will compute and return the coefficient of determination (R^2)\n",
    "    for this data.  numpy.mean() and numpy.sum() might both be useful here, but\n",
    "    not necessary.\n",
    "\n",
    "    Documentation about numpy.mean() and numpy.sum() below:\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html\n",
    "    http://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html\n",
    "    '''\n",
    "    \n",
    "    # your code here\n",
    "    r_squared = 1 - np.sum(np.square(data - predictions)) / np.sum(np.square(data - np.mean(data)))\n",
    "    return r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 3.8\n",
    "import numpy as np\n",
    "import pandas\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "In this question, you need to:\n",
    "1) Implement the linear_regression() procedure using gradient descent.\n",
    "   You can use the SGDRegressor class from sklearn, since this class uses gradient descent.\n",
    "2) Select features (in the predictions procedure) and make predictions.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def normalize_features(features):\n",
    "    ''' \n",
    "    Returns the means and standard deviations of the given features, along with a normalized feature\n",
    "    matrix.\n",
    "    ''' \n",
    "    means = np.mean(features, axis=0)\n",
    "    std_devs = np.std(features, axis=0)\n",
    "    normalized_features = (features - means) / std_devs\n",
    "    return means, std_devs, normalized_features\n",
    "\n",
    "def recover_params(means, std_devs, norm_intercept, norm_params):\n",
    "    ''' \n",
    "    Recovers the weights for a linear model given parameters that were fitted using\n",
    "    normalized features. Takes the means and standard deviations of the original\n",
    "    features, along with the intercept and parameters computed using the normalized\n",
    "    features, and returns the intercept and parameters that correspond to the original\n",
    "    features.\n",
    "    ''' \n",
    "    intercept = norm_intercept - np.sum(means * norm_params / std_devs)\n",
    "    params = norm_params / std_devs\n",
    "    return intercept, params\n",
    "\n",
    "def linear_regression(features, values):\n",
    "    \"\"\"\n",
    "    Perform linear regression given a data set with an arbitrary number of features.\n",
    "    \"\"\"\n",
    "    \n",
    "    ###########################\n",
    "    ### YOUR CODE GOES HERE ###\n",
    "    ###########################\n",
    "    reg = SGDRegressor(n_iter=40)\n",
    "    reg.fit(features, values)\n",
    "    intercept = reg.intercept_\n",
    "    params = reg.coef_\n",
    "    \n",
    "    \n",
    "    return intercept, params\n",
    "\n",
    "def predictions(dataframe):\n",
    "    '''\n",
    "    The NYC turnstile data is stored in a pandas dataframe called weather_turnstile.\n",
    "    Using the information stored in the dataframe, let's predict the ridership of\n",
    "    the NYC subway using linear regression with gradient descent.\n",
    "    \n",
    "    You can download the complete turnstile weather dataframe here:\n",
    "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv    \n",
    "    \n",
    "    Your prediction should have a R^2 value of 0.40 or better.\n",
    "    You need to experiment using various input features contained in the dataframe. \n",
    "    We recommend that you don't use the EXITSn_hourly feature as an input to the \n",
    "    linear model because we cannot use it as a predictor: we cannot use exits \n",
    "    counts as a way to predict entry counts. \n",
    "    \n",
    "    Note: Due to the memory and CPU limitation of our Amazon EC2 instance, we will\n",
    "    give you a random subset (~50%) of the data contained in \n",
    "    turnstile_data_master_with_weather.csv. You are encouraged to experiment with \n",
    "    this exercise on your own computer, locally.\n",
    "    \n",
    "    If you receive a \"server has encountered an error\" message, that means you are \n",
    "    hitting the 30-second limit that's placed on running your program. Try using a\n",
    "    smaller number of features or fewer iterations.\n",
    "    '''\n",
    "    ################################ MODIFY THIS SECTION #####################################\n",
    "    # Select features. You should modify this section to try different features!             #\n",
    "    # We've selected rain, precipi, Hour, meantempi, and UNIT (as a dummy) to start you off. #\n",
    "    # See this page for more info about dummy variables:                                     #\n",
    "    # http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html          #\n",
    "    ##########################################################################################\n",
    "    features = dataframe[['rain', 'precipi', 'Hour', 'meantempi', 'meanwindspdi','meandewpti']]\n",
    "    dummy_units = pandas.get_dummies(dataframe['UNIT'], prefix='unit')\n",
    "    features = features.join(dummy_units)\n",
    "    \n",
    "    # Values\n",
    "    values = dataframe['ENTRIESn_hourly']\n",
    "    \n",
    "    # Get numpy arrays\n",
    "    features_array = features.values\n",
    "    values_array = values.values\n",
    "    \n",
    "    means, std_devs, normalized_features_array = normalize_features(features_array)\n",
    "\n",
    "    # Perform gradient descent\n",
    "    norm_intercept, norm_params = linear_regression(normalized_features_array, values_array)\n",
    "    \n",
    "    intercept, params = recover_params(means, std_devs, norm_intercept, norm_params)\n",
    "    \n",
    "    predictions = intercept + np.dot(features_array, params)\n",
    "    # The following line would be equivalent:\n",
    "    # predictions = norm_intercept + np.dot(normalized_features_array, norm_params)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 4.1\n",
    "from pandas import *\n",
    "from ggplot import *\n",
    "\n",
    "def plot_weather_data(turnstile_weather):\n",
    "    '''\n",
    "    You are passed in a dataframe called turnstile_weather. \n",
    "    Use turnstile_weather along with ggplot to make a data visualization\n",
    "    focused on the MTA and weather data we used in assignment #3.  \n",
    "    You should feel free to implement something that we discussed in class \n",
    "    (e.g., scatterplots, line plots, or histograms) or attempt to implement\n",
    "    something more advanced if you'd like.  \n",
    "\n",
    "    Here are some suggestions for things to investigate and illustrate:\n",
    "     * Ridership by time of day or day of week\n",
    "     * How ridership varies based on Subway station (UNIT)\n",
    "     * Which stations have more exits or entries at different times of day\n",
    "       (You can use UNIT as a proxy for subway station.)\n",
    "\n",
    "    If you'd like to learn more about ggplot and its capabilities, take\n",
    "    a look at the documentation at:\n",
    "    https://pypi.python.org/pypi/ggplot/\n",
    "     \n",
    "    You can check out:\n",
    "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv\n",
    "     \n",
    "    To see all the columns and data points included in the turnstile_weather \n",
    "    dataframe. \n",
    "     \n",
    "    However, due to the limitation of our Amazon EC2 server, we are giving you a random\n",
    "    subset, about 1/3 of the actual data in the turnstile_weather dataframe.\n",
    "    '''\n",
    "    #gg = ggplot(data,aes('yearID','HR')) + geom_point(color ='red')+ geom_line(color='red') + ggtitle('Home Runs Per Year') + xlab('YearID') + ylab('HR')\n",
    "    plot = ggplot(turnstile_weather, aes('Hour','ENTRIESn_hourly')) +\\\n",
    "           geom_point(color = \"blue\") +\\\n",
    "           scale_x_discrete(limits=[0,23]) +\\\n",
    "           ggtitle('NYC Subway ridership by time of day') + xlab('Hour of Day') + ylab('Subway Entries')\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ps 4.2\n",
    "from pandas import *\n",
    "from ggplot import *\n",
    "\n",
    "def plot_weather_data(turnstile_weather):\n",
    "    ''' \n",
    "    plot_weather_data is passed a dataframe called turnstile_weather. \n",
    "    Use turnstile_weather along with ggplot to make another data visualization\n",
    "    focused on the MTA and weather data we used in Project 3.\n",
    "    \n",
    "    Make a type of visualization different than what you did in the previous exercise.\n",
    "    Try to use the data in a different way (e.g., if you made a lineplot concerning \n",
    "    ridership and time of day in exercise #1, maybe look at weather and try to make a \n",
    "    histogram in this exercise). Or try to use multiple encodings in your graph if \n",
    "    you didn't in the previous exercise.\n",
    "    \n",
    "    You should feel free to implement something that we discussed in class \n",
    "    (e.g., scatterplots, line plots, or histograms) or attempt to implement\n",
    "    something more advanced if you'd like.\n",
    "\n",
    "    Here are some suggestions for things to investigate and illustrate:\n",
    "     * Ridership by time-of-day or day-of-week\n",
    "     * How ridership varies by subway station (UNIT)\n",
    "     * Which stations have more exits or entries at different times of day\n",
    "       (You can use UNIT as a proxy for subway station.)\n",
    "\n",
    "    If you'd like to learn more about ggplot and its capabilities, take\n",
    "    a look at the documentation at:\n",
    "    https://pypi.python.org/pypi/ggplot/\n",
    "     \n",
    "    You can check out the link \n",
    "    https://www.dropbox.com/s/meyki2wl9xfa7yk/turnstile_data_master_with_weather.csv\n",
    "    to see all the columns and data points included in the turnstile_weather \n",
    "    dataframe.\n",
    "     \n",
    "   However, due to the limitation of our Amazon EC2 server, we are giving you a random\n",
    "    subset, about 1/3 of the actual data in the turnstile_weather dataframe.\n",
    "    '''\n",
    "    day = turnstile_weather[['DATEn', 'ENTRIESn_hourly']].groupby('DATEn', as_index=False).sum()\n",
    "    \n",
    "    day['Day'] = [datetime.strptime(x, '%Y-%m-%d').strftime('%w %A') for x in day['DATEn']]\n",
    "    \n",
    "    weekday = day[['Day', 'ENTRIESn_hourly']].groupby('Day', as_index=False).sum()\n",
    "    \n",
    "    plot = ggplot(weekday, aes(x='Day', y='ENTRIESn_hourly')) +\\\n",
    "                                      geom_bar(aes(weight='ENTRIESn_hourly'), fill='lightblue',stat='bar') +\\\n",
    "                                      ggtitle('Weekly NYC Subway Ridership') +\\\n",
    "                                      xlab('Day of Week') +\\\n",
    "                                      ylab('Subway entries')\n",
    "\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
